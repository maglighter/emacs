*Java Learning*

* changes across versions
https://habr.com/ru/post/500468/
* equals, hashCode implementation
  
  1) Reflexive : Object must be equal to itself.
  2) Symmetric : if a.equals(b) is true then b.equals(a) must be true.
  3) Transitive : if a.equals(b) is true and b.equals(c) is true then
     c.equals(a) must be true.
  4) Consistent : multiple invocations of equals() method must return
     the same value until any of properties are modified. So if two
     objects are equals in Java they will remain equals until any of
     their property is modified.
  5) Null comparison : comparing any object to null must be false and
     should not result in NullPointerException. For example
     a.equals(null) must be false, passing unknown object, which could
     be null, to equals in Java is is actually a Java coding best
     practice to avoid NullPointerException in Java.

  Implementation steps:
  1) Do this check -- if yes then return true.
  2) Do null check -- if yes then return false.
  3) Do the instanceof check or better class check

  #+BEGIN_SRC java
  if((obj == null) || (obj.getClass() != this.getClass())) {
      return false;
  }
  #+END_SRC

  4) Type cast the object; note the sequence instanceof check must be
  prior to casting object.
  5) Compare individual attribute starting with numeric
     attribute. It’s also worth to remember doing null check on
     individual attribute before calling equals() method on them
     recursively to avoid NullPointerException during equals check in
     Java.

  Example:
  #+BEGIN_SRC java
    @Override
    public boolean equals(Object obj) {
        if (obj == this) {
            return true;
        }
        if (obj == null || obj.getClass() != this.getClass()) {
            return false;
        }

        Person guest = (Person) obj;
        return id == guest.id
                && (firstName == guest.firstName 
                     || (firstName != null && firstName.equals(guest.getFirstName())))
                && (lastName == guest.lastName 
                     || (lastName != null && lastName .equals(guest.getLastName())));
    }
    
    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result
                + ((firstName == null) ? 0 : firstName.hashCode());
        result = prime * result + id;
        result = prime * result
                + ((lastName == null) ? 0 : lastName.hashCode());
        return result;
    }
  #+END_SRC     
* Optional
https://blogs.oracle.com/javamagazine/12-recipes-for-using-the-optional-class-as-its-meant-to-be-used
* Streams
*example of chunking to groups {0=[12, 11, 10], 1=[9, 8, 7], 2=[6, 5]}*
#+begin_src java
AtomicInteger counter = new AtomicInteger();
Map<Integer, List<Integer>> collect = Arrays.stream(a)
.boxed() // convert from IntStream
.sorted(Comparator.reverseOrder()) // reversing
.collect(Collectors.groupingBy(x -> counter.getAndIncrement()/3));
#+end_src
* blogs
[[https://deepakvadgama.com/]] Spring
 [[https://vladmihalcea.com/]] Hibernate, JPA performance
* to learn
  * executor framework
    + A Future that may be explicitly completed (setting its value and status), and may be used as a CompletionStage, supporting dependent functions and actions that trigger upon its completion.
      #+BEGIN_SRC java
      public Future<String> calculateAsync() throws InterruptedException {
    CompletableFuture<String> completableFuture = new CompletableFuture<>();
 
    Executors.newCachedThreadPool().submit(() -> {
        Thread.sleep(500);
        completableFuture.complete("Hello");
        return null;
    });
 
    return completableFuture;
}
      #+END_SRC
      [[https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html]]
* core
** memory model
*** reference escaping
When the method of a class returns a reference to a collection - it is called reference escaping:

#+begin_src java
public Map<String, Customer> getCustomers() {
		return this.records;
}
#+end_src

It is possible to solve it partially by providing iterator (=implements Iterable<Customer>= and provede iterator() method) but changes to collections are still possible (ex. remove()).

The best way is to return =Collection.unmodifiebleMap(records)= which will prevent collection modification.

For other objects it is possible to return read-only interfaces of an object.
*** garbage collection
*Mark and Sweep strategy*
During mark stage all threads are stoped (stop the world event) and all object linked from stack variables marked as "live". All other objects marked as "dead"

*Generational garbage collection*
More complex model based on assumptions:
+ Most objects don't live for long
+ If an objec survives it is likely to live forever

The heap divided on two halves: young ([Eden,s0,s1], very small size, easy to clear) and old (big one). When gc happens it finds survived objects from the young and moves it to the old. Old gc happens only if memory is full.
** repo
[[https://github.com/DeepakVadgama/java-interview/blob/master/topics/core/]]

*** Default init values

- For fields (class level variables), values are auto assigned default values. 
- Method local variables should be manually assigned. 
- Default values (references = null, primitives = 0, boolean = false)
- Arrays initialize its elements: int[] numbers = new int[10]; will assign all ints in the array to 0.

*** String pool

- String constants are placed in a memory pool 
- When retrieved, returns reference to string in the pool. 
- Pool saves memory. New string constants with same value share same instance in the pool.
- String is immutable thus these values are never changed. For any updates, new string constant is created.  
- String s = "abc" will place "abc" in pool and return its reference.
- String s = new String("abc") will also place "abc" in pool, as well as allocate new memory
- [implementation details](jvm-internals.md#string-interning)

*** Wrapper class pool

- Boolean
- Byte
- Character from \u0000 to \u007f (7f is 127 in decimal)
- Short and Integer from –128 to 127

*** Singleton options

- Using: static final variable (init guarantee)
- Using: Lazy loading (double checked) 
- Using: Enums (by default lazy, and init guarantee)

*** Override method rules

- Same method name and parameter types
- Same or a subset of super methods' checked exceptions
- Any number of runtime exceptions
- Same or covariant return type 

*** Covariant variables

- Variable types which are compatible. 
- Eg: an int is covariant of long
- Eg: an Lion class is covariant of Animal class (only if Lion extends Animal)
- Can be used in parameters, return types or assignments

*** Varargs, boxing, widening

- Primitive Widening > Boxing > Varargs. [Example](http://stackoverflow.com/a/2128068/3494368). 
- Widening then Boxing not allowed. 
- Boxing then Widening allowed.   
- Widening between wrapper classes not allowed (eg: Long n = new Integer(10); not allowed)
 
*** Inner classes

Personally I find this part of Java to be super annoying, unnecessary and hardly ever used in real-life (especially after Java 8). 
Also, this topic does not come up a lot in interviews, so just skimp through. 

- Inner class: Can access enclosing class's variables (even private ones)
- Method local inner class: Same as above. Plus, it can access final variables in encapsulating method. 
- Anonymous inner class: Just no name, otherwise same as above. 
- Static inner class: No special relationship with outer class. 

*** Reference types

- **Weak reference** - Eligible for GC if object not referenced by any other variables. Good for caches. Are enqueued in ReferenceQueue just before GC (object can be resurrected in finalize). Returns null once object is eligible for GC, even if object is resurrected, the weak-reference still is dead, and will return null. 
- **Soft reference** - Same as above, but its GC’ed only when memory is low. Excellent for caches.
- **Phantom reference** - Even after GC, it references the object, until the memory is reclaimed. Enqueued in ReferenceQueue after complete reclamation. Always returns null, so that you cannot resurrect it. Can be helpful to check when memory is reclaimed so that you can load next large object. 
- **WeakHashMap** - Weak keys. Removes entry once key is GC’ed.
 
*** Cloning  

- clone method (protected) of Object class returns shallow copy. Need to be explicitly cast back.
- Requires class to implement Cloneable marker interface. Else returns CloneNotSupportedException
- Singletons should override clone method and throw CloneNotSupportedException
- [More details](../design/effective-java.md#
* DI
** Definition
Dependency injection (DI) is a process whereby objects define their dependencies, that is, the other objects they work with, only through constructor arguments, arguments to a factory method, or properties that are set on the object instance after it is constructed or returned from a factory method. The container then injects those dependencies when it creates the bean. This process is fundamentally the inverse, hence the name Inversion of Control (IoC), of the bean itself controlling the instantiation or location of its dependencies on its own by using direct construction of classes, or the Service Locator pattern.

The Spring Framework Inversion of Control (IoC) component is the nucleus of the framework. It uses dependency injection to assemble Spring-provided (also called infrastructure components) and development-provided components in order to rapidly wrap up an application.

** Advantages of Dependency Injection
The advantages of DI are as follows:
*** Loosely coupled architecture.
*** Separation of responsibility.
*** Configuration and code are separate.
*** A different implementation can be supplied using configuration without changing the code dependent.
*** Improves testability.
*** DI allows you to replace actual objects with mock objects. This improves testability by writing simple JUnit tests that use mock objects.
* Debugging
[[https://www.jetbrains.com/help/idea/tutorial-java-debugging-deep-dive.html]]
* Basic
+ encapsulation
is the idea of combining fields and methods in
a class such that the methods operate on the data, as opposed to the users of the class
accessing the fields directly. In Java, it is commonly implemented with private instance
members that have public methods to retrieve or modify the data, commonly referred to
as getters and setters, respectively.
* Regexp
{n} - number of matches

/s - matches any whitespace characters such as space and tab
/S - matches any non-whitespace characters
/d - matches any digit character
/D - matches any non-digit characters
/w - matches any word character (basically alpha-numeric)
/W - matches any non-word character
/b - matches any word boundary (this would include spaces, dashes, commas, semi-colons, etc)
[abc], [^abc] - range and negative range

*Java Examples*
#+begin_src java
Pattern p = Pattern.compile("a*b");
Matcher m = p.matcher("aaaaab");
boolean b = m.matches();
String[] parts = pattern.split("aaaaab");
// single execution
boolean b = Pattern.matches("a*b", "aaaaab");
// groups
if (m.find()) {
    m.group(1);
}
// replace
String text = "Егор Алла Анна";
Pattern pattern = Pattern.compile("А.+?а");
Matcher matcher = pattern.matcher(text);
while (matcher.find()) {
    int start=matcher.start();
    int end=matcher.end();
    System.out.println("Найдено совпадение " + text.substring(start,end) + " с "+ start + " по " + (end-1) + " позицию");
}
System.out.println(matcher.replaceFirst("Ира")); // Егор Ира Анна
System.out.println(matcher.replaceAll("Ольга")); // Егор Ольга Ольга

#+end_src

* Concurrency
Николай Алименков — Прикладная многопоточность
https://www.youtube.com/watch?v=8piqauDj2yo

** Theory
work - time to execute all steps in all graph
span - maximum length of edge
work / span - ideal parallelism

Tp (execution time on p number of processes)
T1 = work, Tinf = span, Tinf <= Tp <= T1

speedup = T1 / Tp, speedup <= P
speedup <= work / span = ideal parallelism

*** Amdahls's Law

q = fraction of WORK in a parrallel program that must be executed sequentialy
[ best speedup(P) <= 1 / q ]

Ex:
q = 0.5 -> speedup <= 2
q = 0.1 -> speedup <= 10

span >= q * work
speedup = T1 /Tp <= work / q * work <= 1/q>

*** Memoization
remembering Feature values instead of the values and when they are needed - calculate them
if they weren't calculated or return calculated

Pascal's triangle as an example

*** Determinism
functionally deterministic if it always computes the same answer when given the same input
structurally deterministic if it always computes the same computation graph, when given the same input.

** ForkJoinPool
compute method, extends RecursiveAction
invokeAll(left, right)

or:
L.fork
R.compute
L.join
res = L.sum + R.sum
* Spring
https://reflectoring.io/spring-boot-12-factor-app/

** Useful Annotations
@Autowired
@Component, @Service, @Repository, @Configuration, @RestController
@Primary - mark default Bean implementation if there are several

** Test Annotations
• @BootstrapWith - Class-level annotation to configure how the test context is bootstrapped
• @ContextConfiguration - Class-level annotation to configure the application context
• @WebAppConfigurtation - Class-level annotation to configure a web application context
• @ContextHiearchy - Class-level annotation to set multiple @ContextConfigurations
• @ActiveProfiles - Class-level annotation to set active profiles for test
• @TestPropertySource - Class-level annotation to set property sources for test
• @DirtiesContext - Class or method level annotation which tells Spring to re-load context after test - (slows down your tests)
• @TestExecutionListeners - Used to configure test execution listeners
• @Commit - Class or method level annotation to commit action of test to database.
• @Rollback - Class or method level annotation to rollback action of test from database.
• @BeforeTransaction - run a method which returns void before a transaction is started
• @AfterTransaction - run a method which returns void after a transaction has completed
• @Sql - Used to configure SQL scripts to run before a test
• @SqlConfig - Configuration for the parsing of SQL scripts
• @SqlGroup - Configure a grouping of SQL scripts

Junit

• @SpringJUnitConfig - Combines @ContextConfiguration with
@ExtendWith(SpringExtension.class) to configure the Spring Context for the test
• @SpringJUnitWebConfig - Combines @ContextConfiguration and @WebAppConfiguration with
@ExtendWith(SpringExtension.class) to configure the Spring Context for the test
• @EnabledIf - Conditional execution of test
• @DisabledIf - Conditional execution of test

** Example matcher
ExampleMatcher matcher = ExampleMatcher.matching().withIgnoreCase()
				.withMatcher("email", GenericPropertyMatcher::contains)
				.withMatcher("role", GenericPropertyMatcher::contains)
				.withMatcher("enabled", GenericPropertyMatcher::exact);
		Example<User> example = Example.of(user, matcher);
		return userRepository.findOne(example);
** Transactions

+ Learn ACID
  - Atomicity
  - Consistency
  - Isolation
  - Durability

+ transactions, hibernate, locking (pes, opt)    
https://www.youtube.com/watch?v=dFASbaIG-UU

[[https://codete.com/blog/5-common-spring-transactional-pitfalls/]]

+ When method is @Transactional - changed entities are saved automatically, no need to call save()
+ The invocation of @Transactional method  must come from outside of the bean. It should be =public=

The way to handle this situation:
#+begin_src java
@Service
public class UserService {
   @PersistenceContext
   private EntityManager entityManager;
 
   @Autowired
   private UserService _self; // proxy reference injected
 
   public User createUser(String name) {
       User newUser = new User(name);
       return _self.saveUser(newUser);
   }
 
   @Transactional
   public User saveUser(User newUser) {
       entityManager.persist(newUser);
       return newUser;
   }
}
#+end_src
+ By default a transaction will be rolled back if any unchecked exception is thrown within it, whereas checked exceptions don’t trigger rollbacks.
  Customize this behaviour with parameters:
  =noRollbackFor= – to specify runtime exception, which shouldn’t cause rollback
  =rollbackFor= – to indicate which checked exception should trigger rollbacks

*** Propagation
=REQUIRED= is the default propagation. Spring checks if there is an active transaction, then it creates a new one if nothing existed. Otherwise, the business logic appends to the currently active transaction

For =SUPPORTS=, Spring first checks if an active transaction exists. If a transaction exists, then the existing transaction will be used. If there isn't a transaction, it is executed non-transactional

When the propagation is =MANDATORY=, if there is an active transaction, then it will be used. If there isn't an active transaction, then Spring throws an exception

For transactional logic with =NEVER= propagation, Spring throws an exception if there's an active transaction:

=NOT_SUPPORTED= Propagation - Spring at first suspends the current transaction if it exists, then the business logic is executed without a transaction.

When the propagation is =REQUIRES_NEW=, Spring suspends the current transaction if it exists and then creates a new one

NESTED propagation, Spring checks if a transaction exists, then if yes, it marks a savepoint. This means if our business logic execution throws an exception, then transaction rollbacks to this savepoint. If there's no active transaction, it works like REQUIRED.

*** Isolation
+ =Default= - default for RDBMS (PostgreSQL - Read Commited)
+ =Read Committed= - does not allow dirty reads.
+ =Read Uncommitted= - allows dirty reads.
+ =Repeatable Read= - if a row is read twice in the same transaction, the result will always be the same.
+ =Serializable= - Performs all transactions in a sequence.

*Dirty read*

  thread 1   thread 2      
      |         |
    write(x)    |
      |         |
      |        read(x)
      |         |
    rollback    |
      v         v 

value (x) is now dirty (incorrect)

*** Examples
[[https://stackoverflow.com/questions/8490852/spring-transactional-isolation-propagation]]
PROPAGATION_REQUIRED = 0; If DataSourceTransactionObject T1 is already started for Method M1.If for another Method M2 Transaction object is required ,no new Transaction object is created .Same object T1 is used for M2

PROPAGATION_MANDATORY = 2; method must run within a transaction. If no existing transaction is in progress, an exception will be thrown

PROPAGATION_REQUIRES_NEW = 3; If DataSourceTransactionObject T1 is already started for Method M1 and it is in progress(executing method M1) .If another method M2 start executing then T1 is suspended for the duration of method M2 with new DataSourceTransactionObject T2 for M2.M2 run within its own transaction context

PROPAGATION_NOT_SUPPORTED = 4; If DataSourceTransactionObject T1 is already started for Method M1.If another method M2 is run concurrently .Then M2 should not run within transaction context. T1 is suspended till M2 is finished.

PROPAGATION_NEVER = 5; None of the methods run in transaction context.

An isolation level: It is about how much a transaction may be impacted by the activities of other concurrent transactions.It a supports consistency leaving the data across many tables in a consistent state. It involves locking rows and/or tables in a database.

The problem with multiple transaction

Scenario 1.If T1 transaction reads data from table A1 that was written by another concurrent transaction T2.If on the way T2 is rollback,the data obtained by T1 is invalid one.E.g a=2 is original data .If T1 read a=1 that was written by T2.If T2 rollback then a=1 will be rollback to a=2 in DB.But,Now ,T1 has a=1 but in DB table it is changed to a=2.

Scenario2.If T1 transaction reads data from table A1.If another concurrent transaction(T2) update data on table A1.Then the data that T1 has read is different from table A1.Because T2 has updated the data on table A1.E.g if T1 read a=1 and T2 updated a=2.Then a!=b.

Scenario 3.If T1 transaction reads data from table A1 with certain number of rows. If another concurrent transaction(T2) inserts more rows on table A1.The number of rows read by T1 is different from rows on table A1

Scenario 1 is called Dirty reads.

Scenario 2 is called Non-repeatable reads.

Scenario 3 is called Phantom reads.

So, isolation level is the extend to which Scenario 1, Scenario 2, Scenario 3 can be prevented. You can obtain complete isolation level by implementing locking.That is preventing concurrent reads and writes to the same data from occurring.But it affects performance .The level of isolation depends upon application to application how much isolation is required.

ISOLATION_READ_UNCOMMITTED :Allows to read changes that haven’t yet been committed.It suffer from Scenario 1, Scenario 2, Scenario 3

ISOLATION_READ_COMMITTED:Allows reads from concurrent transactions that have been committed. It may suffer from Scenario 2 and Scenario 3. Because other transactions may be updating the data.

ISOLATION_REPEATABLE_READ:Multiple reads of the same field will yield the same results untill it is changed by itself.It may suffer from Scenario 3.Because other transactions may be inserting the data

ISOLATION_SERIALIZABLE: Scenario 1,Scenario 2,Scenario 3 never happens.It is complete isolation.It involves full locking.It affets performace because of locking.

*** Testing transactions
#+begin_src java
@Component
public class ExampleClient {
    @Autowired
    private ArticleRepository repo;
    @Autowired
    private Tasks tasks;

    public ExecutorService run() {
        //creating and persisting an Article
        Article article = new Article("test article");
        repo.save(article);

        ExecutorService es = Executors.newFixedThreadPool(2);

        //user 1, reader
        es.execute(tasks::runUser1Transaction);

        //user 2, writer
        es.execute(tasks::runUser2Transaction);

        return es;
    }

    @Service
    @Transactional
    public class Tasks {
        public void runUser1Transaction() {
            System.out.println(" -- user 1 reading Article entity --");
            long start = System.currentTimeMillis();
            Article article1 = null;
            try {
                article1 = repo.findArticleForRead(1L);
            } catch (Exception e) {
                System.err.println("User 1 got exception while acquiring the database lock:\n " + e);
                return;
            }
            System.out.println("user 1 got the lock, block time was: " + (System.currentTimeMillis() - start));
            //delay for 2 secs
            ThreadSleep(3000);
            System.out.println("User 1 read article: " + article1);
        }

        public void runUser2Transaction() {
            ThreadSleep(500);//let user1 acquire optimistic lock first
            System.out.println(" -- user 2 writing Article entity --");
            long start = System.currentTimeMillis();
            Article article2 = null;
            try {
                article2 = repo.findArticleForWrite(1L);
            } catch (Exception e) {
                System.err.println("User 2 got exception while acquiring the database lock:\n " + e);
                return;
            }
            System.out.println("user 2 got the lock, block time was: " + (System.currentTimeMillis() - start));
            article2.setContent("updated content by user 2.");
            repo.save(article2);
            System.out.println("User 2 updated article: " + article2);
        }

        private void ThreadSleep(long timeout) {
            try {
                Thread.sleep(timeout);
            } catch (InterruptedException e) {
                System.err.println(e);
            }
        }
    }

    public static void main(String[] args) throws InterruptedException {
        AnnotationConfigApplicationContext context =
                new AnnotationConfigApplicationContext(AppConfig.class);
        ExampleClient exampleClient = context.getBean(ExampleClient.class);
        ExecutorService es = exampleClient.run();
        es.shutdown();
        es.awaitTermination(5, TimeUnit.MINUTES);
        EntityManagerFactory emf = context.getBean(EntityManagerFactory.class);
        emf.close();
    }
}
#+end_src

** ApplicationContext vs BeanFactory
The Spring Framework comes with two IOC containers – BeanFactory and ApplicationContext. The BeanFactory is the most basic version of IOC containers, and the ApplicationContext extends the features of BeanFactory.

ApplicationContext enhances BeanFactory in a more framework-oriented style and provides several features that are suitable for enterprise applications.

For instance, it provides messaging (i18n or internationalization) functionality, event publication functionality, annotation-based dependency injection, and easy integration with Spring AOP features.

Apart from this, the ApplicationContext supports almost all types of bean scopes, but the BeanFactory only supports two scopes — Singleton and Prototype. Therefore, it's always preferable to use ApplicationContext when building complex enterprise applications.
** Angular integration and Security
Single page application
https://spring.io/guides/tutorials/spring-security-and-angular-js/

https://www.marcobehler.com/guides/spring-security

https://vaadin.com/learn/tutorials/modern-web-apps-with-spring-boot-and-vaadin/adding-a-login-screen-to-a-vaadin-app-with-spring-security
#+begin_src java
@Override
protected void configure(HttpSecurity http) throws Exception {
    http.csrf().disable()  
        .requestCache().requestCache(new CustomRequestCache()) 
        .and().authorizeRequests() 
        .requestMatchers(SecurityUtils::isFrameworkInternalRequest).permitAll()  

        .anyRequest().authenticated()  

        .and().formLogin()  
        .loginPage(LOGIN_URL).permitAll()
        .loginProcessingUrl(LOGIN_PROCESSING_URL)  
        .failureUrl(LOGIN_FAILURE_URL)
        .and().logout().logoutSuccessUrl(LOGOUT_SUCCESS_URL); 
}
#+end_src
* SQL
normal forms,
ACID,
isolation levels,
index anatomy
* Hibernate
[[https://thoughts-on-java.org/ultimate-guide-association-mappings-jpa-hibernate/]]
*ManyToOne, OneToMany with examples*
https://docs.jboss.org/hibernate/orm/5.1/userguide/html_single/chapters/domain/associations.html
* Testing
+ Isolated beans loading
  #+begin_src java
  @SpringBootTest(classes = TestEnv.class)
  public class TestClass {

  }

  @Configuration
  @ComponentScan(lazyInit = true)
  public class TestEnv {}
  #+end_src
  
+ Junit5
@Before/AfterAll static method
@BeforeEach/AfrerEach void setUp() {}

+ Mockito
@ExtendsWith(MockitoExtension.class) [class-level]
@Mock MockingDep dep;
@InjectMocks MockingService service; [will inject MockingDep]

// given
given(service.findById(anyLong())).willReturn(5L);

// when

Long result = service.findById(3L);

// then
then(service).should().someMethod();
* kafka                                                               :drill:
SCHEDULED: <2020-05-12 Tue>
:PROPERTIES:
:ID:       a3dae03c-2e7a-484d-b970-cb5114cb9797
:DRILL_LAST_INTERVAL: 3.86
:DRILL_REPEATS_SINCE_FAIL: 2
:DRILL_TOTAL_REPEATS: 1
:DRILL_FAILURE_COUNT: 0
:DRILL_AVERAGE_QUALITY: 3.0
:DRILL_EASE: 2.36
:DRILL_LAST_QUALITY: 3
:DRILL_LAST_REVIEWED: [2020-05-08 Fri 16:50]
:END:
Kafka is a distributed streaming platform that stores records in a durable way through replicating records across multiple servers.

To divide a topic between multiple servers, we need a way to split a topic into smaller substreams. These substreams are called =partitions=. Whenever a service produces a new record, this service gets to decide which partition the record should land on.

The default partitioner hashes the message key and modulos that over the number of partitions: That way messages with the same key always end up on the same partition.

Each consumer keeps track of which records it has processed. Since records are processed in order, a simple offset is enough. Every once in a while (5 seconds by default), a consumer will commit its offset to Kafka.

Topics consist of =partitions=, that store records in order. Partitioners decide which records belong on which partitions. Consumer groups are optional, and help distribute partitions among consumers for scalability. Offsets are committed as checkpoints for when consumers crash.

[[https://hackernoon.com/understanding-kafka-with-factorio-74e8fc9bf181][kafka]] blog post
* example projects
https://github.com/vogellacompany/codeexamples-javaweb
* Spring Microservices in Action                                       :book:
** Type of clouds

[[./attachments/type-of-clouds.png]]
** Microservices properties
**A microservice architecture has the following characteristics**
+ Application logic is broken down into small-grained components with welldefined boundaries of responsibility that coordinate to deliver a solution. 
+ Each component has a small domain of responsibility and is deployed com pletely independently of one another. Microservices should have responsibility for a single part of a business domain. Also, a microservice should be reusable across multiple applications.
+ Microservices communicate based on a few basic principles (notice I said principles, not standards) and employ lightweight communication protocols such as HTTP and JSON (JavaScript Object Notation) for exchanging data between the service consumer and service provider. 
+ The underlying technical implementation of the service is irrelevant because the applications always communicate with a technology-neutral protocol (JSON is the most common). This means an application built using a microservice application could be built with multiple languages and technologies.
+ Microservices—by their small, independent, and distributed nature—allow organizations to have small development teams with well-defined areas of responsibility. These teams might work toward a single goal such as delivering an application, but each team is responsible only for the services on which they’re working.
  **properties**
+ /Flexible—Decoupled/ services can be composed and rearranged to quickly deliver new functionality. The smaller the unit of code that one is working with, the less complicated it is to change the code and the less time it takes to test deploy the code.
  
+ /Resilient—Decoupled/ services mean an application is no longer a single “ball of mud” where a degradation in one part of the application causes the whole application to fail. Failures can be localized to a small part of the application and contained before the entire application experiences an outage. This also enables the applications to degrade gracefully in case of an unrecoverable error.
  
+ /Scalable—Decoupled/ services can easily be distributed horizontally across multiple servers, making it possible to scale the features/services appropriately. With a monolithic application where all the logic for the application is intertwined, the entire application needs to scale even if only a small part of the application is the bottleneck. Scaling on small services is localized and much more cost- effective.
  
** Request processing

[[./attachments/request-processing.png]]
** Security
*** Token security
[[./attachments/token-security.png]]
* java options
https://success.docker.com/article/java-app-is-killed-by-docker
+ Java 8
docker run -m 400MB openjdk:8 java -XX:MaxRAM=400m -Xmx300m -XX:MaxRAMFraction=1 -XshowSettings:vm
*or*
docker run -m 400MB openjdk:8 java -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=1 -XshowSettings:vm

+ Java 10
docker run -m 400MB openjdk:10 java -XshowSettings:vm -XX:MaxRAMFraction=1
* Patterns
+ will collect all components that implement Handler
@Autowired
List<Handler> handlers;
* REST
Аббревиатура =REST= расшифровывается как representational state transfer — «передача состояния представления» или, лучше сказать, представление данных в удобном для клиента формате. Термин “REST” был введен Роем Филдингом в 2000 г. Основная идея REST в том, что каждое обращение к сервису переводит клиентское приложение в новое состояние. По сути, REST — не протокол и не стандарт, а подход, архитектурный стиль проектирования API. 

Любой ресурс имеет ID, по которому можно получить данные.
Сервер не хранит состояние — это значит, сервер не отделяет один вызов от другого, не сохраняет все сессии в памяти.
Методы POST и PUT должны возвращать обратно объект, который они изменили или создали, — это позволит сократить время обращения к сервису вдвое.

*Коды статусов*

Возвращайте соответствующие http коды статуса в каждом ответе. Успешные ответы должны содержать следующие коды:
200 — для GET запроса и для синхронных DETELE и PATCH
201 — для синхронного POST запроса
202 — для асинхронных POST, DELETE и PATCH запросов
206 — для успешного частичного ответа на GET запрос

Уделите внимание ошибкам аутентификации и прав доступа:

401 Unautorized — пользователь не авторизован
403 Forbidden — доступ запрещен из-за недостатка прав
Дополнительные коды, указывающие на ошибки:

422 Unprocessable Entity — запрос корректный, но содержит неверные параметры
429 Too Many Requests — превышено лимит частоты подключений, попробуйте позже
500 Internal Server Error — Внутренняя ошибка сервера, можно обращаться к администратору

*Headers*

Рекомендуется при проектировании REST-сервисов явно указывать заголовки, в которых обозначен формат обмена данными:
Content-Type - формат запроса;
Accept - список форматов ответа.

Используйте пути и имена только в нижнем регистре и только тире в качестве разделителя слов:
myservice-api.ru/users
myservice-api.ru/app-setups

Для атрибутов также желательно использование нижнего регистра, но необходимо использование символа подчеркивания в качестве разделителя, для совместимости с JavaScript. Например:
service_class: "first"

Форматируйте время по стандарту ISO8601
Прием и отправка даты/времени должны осуществляться только в UTC. Формат должен соответствовать ISO8601:
"finished_at": "2014-01-01T15:00:00Z"

*Структурируйте информацию об ошибках*

Создавайте последовательные и структурированные ответы при возникновении ошибок. Включайте идентификатор id типа ошибки, краткое описание message и url, указывающий на подробную информацию по данной ошибке:
HTTP/1.1 429 Too Many Requests
{
  "id":      "rate_limit",
  "message": "Account reached its API rate limit.",
  "url":     "https://docs.service.com/rate-limits"
}
Документируйте формат сообщений об ошибках и все возможные типы ошибок, которые может получить клиент.


Действия над ресурсами, обычно, определяются стратегией CRUD и соответствуют HTTP-методам следующим образом:

GET /api/users — получить список пользователей;
GET /api/users/123 — получить указанного пользователя;
POST /api/users — создать нового пользователя;
PUT /api/users/123 — обновить все данные указанного пользователя;
PATCH /api/users/123 — частично обновить данные пользователя;
DELETE /api/users/123 — удалить пользователя.
Если ресурс существует только в контексте другого ресурса, то URL может быть составным:

GET /api/posts/9/comments — получить список комментариев к записи №9;
GET /api/posts/9/comments/3 — получить комментарий №3 к записи №9.
Когда действие над объектом не соответствует CRUD операции, то его можно рассматривать как составной ресурс:

POST /api/posts/9/like — отметить запись №9 как понравившуюся;
DELETE /api/posts/9/like — снять отметку «понравилось» с записи №9.
Действия по созданию и обновлению ресурсов должны возвращать ресурс

Методы POST, PUT или PATCH могут изменять поля ресурса, которые не были включены в запрос (например, ID, дата создания или дата обновления). Чтобы не вынуждать пользователя API выполнять ещё один запрос на получение обновлённых данных, такие методы должны вернуть их в ответе.

URL по сути является первичным ключом для единицы данных. То есть, например, вторая книга с книжной полки будет иметь вид /books/2, а 41 страница в этой книге — /books/2/pages/41. Отсюда и получается строго заданный формат. Причем совершенно не имеет значения, в каком формате находятся данные по адресу /books/2/pages/41 – это может быть и HTML, и отсканированная копия в виде jpeg-файла, и документ Word.
Рекомендуется при определении имени REST-сервиса использовать имена ресурсов во множественном числе. Такой подход позволяет добавлять новые REST-сервисы лишь расширяя имена уже существующих. Например, сервис /books вернёт нам список всех книг, /books/3 вернёт информацию о 3-ей книге, а сервис /books/3/pages вернёт все страницы 3-ей книги.

Фильтрация
Например, чтобы вывести все красные книги необходимо выполнить запрос:
GET /books?color=red

Сортировка
Например, чтобы вывести все книги, отсортированные по году публикации по убыванию и по названию по возрастанию нужно выполнить следующий запрос:
GET /books?sort=-year,+name

Пагинация
 в REST API должен быть предусмотрен функционал пагинации. Реализуется он с помощью знакомых нам по SQL параметрам limit и offset. Например:
GET /books?offset=10&limit=5

Поммо того хорошим тоном является вывод ссылок на предыдущую, следующую, первую и последнюю страницы в хидере Link. Например:
Link: <http://localhost/api/books?offset=15&limit=5>; rel="next",
<http://localhost/api/books?offset=50&limit=3>; rel="last",
<http://localhost/api/books?offset=0&limit=5>; rel="first",
<http://localhost/api/books?offset=5&limit=5>; rel="prev"
Рекомендуется также возвращать общее количество ресурсов в хидере X-Total-Count.

Выбор полей ресурса
Для более удобного использования сервиса, для экономии трафика можно предоставить возможность управлять форматом вывода данных. Реализуется предоставлением возможности выбора полей ресурса, которые должен вернуть REST сервис. Например, если необходимо получить только id книг и их цвета, необходимо выполнить следующий запрос:
GET /books?fields=id,color

*Версионность*

Хорошим тоном является поддержка версионности REST API. Это позволит в дальнейшем легко расширять API, без обязательного внесения изменений в клиенты, которые уже пользуются им.
Имеются несколько подходов реализации версионности:

С использованием Accept хидера. В данном случае версия API указывается в Accept - Accept:text/v2+json
С использованием URI. В таком подходе версия API указывается прямо в URI - http://localhost/api/v2/books
Использование кастомного хидера. Можно использовать собственный хидер, который будет отвечать только за передачу версии API - API-Version:v2
Использование параметра запроса. Можно использовать параметр запроса для передачи версии API - /books?v=2

*Обработка исключений*

{
   "code" : 1234,
   "message" : "Something bad happened :(",
   "description" : "More details about the error here",
   “moreInfo”: “http:/localhost/api/v2/errors/1234”
}


// Full URL, with query string
$request->fullUrl()

// Just the path part of the URL 
$request->path()

// Just the root (protocol and domain) part of the URL)
$request->root()
* CI/CD
Процесс CI/CD (Continuous Integration / Continuous Delivery) нацелен на максимально
автономную, полную и быструю сборку приложений из исходного кода (далее, «CI») и
разворачивание его на специализированном под определённые задачи серверном
оборудовании (далее, «CD»).

*Процесс CI строиться в следующем порядке:*
1. Написание и хранение исходного кода
2. Сборка приложения из исходного кода
3. Тестирование сборки (полное и частичное)
4. Хранение сборки под некой версией
5. Сборка и хранение сборки в виде Docker-образа.
   
*Процесс СD, кроме выполнения части СI, также имеет дополнительные этапы:*
1. Разворачивание экземпляра приложения на серверном оборудовании
2. DEV-стенд
3. TEST-стенд
4. DEMO-стенд
5. PROD-зона. 
* SOLID
*Single responsibility (SRP)*
Принцип единственной ответственности 
*Open-closed (OCP)*
Принцип открытости/закрытости 
*Liskov substitution (LSP)*
Принцип подстановки Барбары Лисков - замена в коде экземпляров класов на экземпляры их подклассов (наследников) не должна влиять на правильность работы 
*Interface segregation (ISP)*
Принцип разделения интерфейса - много интерфейсов, предназначенных для разных пользователей (других классов) лучше одного большого интерфейса, в который свален весь функционал
*Dependency inversion (DIP)*
Принцип инверсии зависимости - зависимости классов должны опираться на абстракцию, зависимости не должны опираться на конкретную реализацию

* Collections

[[./attachments/java-collections.jpeg]]

*HashMap*
map.merge(word, 1, (prev, one) -> prev + one)
map.putIfAbsent(key, value)
map.getOrDefault(key, default)
* Interview questions
+ =Fail-fast= (ArrayList, HashMap, etc) and =Fail-safe= (creates a copy of the original collection or object array and iterates over that copied collection, ConcurrentHashMap, CopyOnWriteArrayList) iterators in Java
+ =Closures= (lambdas which could access variables defined out of scope of a function)
+ =Coupling= refers to the knowledge or information or dependency of another class. It arises when classes are aware of each other. If a class has the details information of another class, there is strong coupling. In Java, we use private, protected, and public modifiers to display the visibility level of a class, method, and field. You can use interfaces for the weaker coupling because there is no concrete implementation.
+ =Cohesion= refers to the level of a component which performs a single well-defined task. A single well-defined task is done by a highly cohesive method. The weakly cohesive method will split the task into separate parts. The java.io package is a highly cohesive package because it has I/O related classes and interface. However, the java.util package is a weakly cohesive package because it has unrelated classes and interfaces.
+ https://www.toptal.com/java/interview-questions
+ https://www.omni-academy.com/java-interview-questions-and-answers-in-germany/
** EPAM  
RDBMS  базовый SQL, join, limit
RDBMS  индексы
RDBMS  агрегаты, группировка
RDBMS  триггеры, хранимки, constraints
RDBMS  анализ запроса и состояния БД
RDBMS  нестандартные возможности RDBMS
Data Access  Spring Data, JPA, jpql
Data Access  Транзакции
Data Access  NoSQL
Java core  ООП, constructors, overloading
Java core  Типы исключений, try-finally 
Java core  Java Collections, O(n)
Java core  JVM, Garbage Collector
Java core  Потокобезопасность, volatile
Java core  java 8, lambdas
Бизнес-логика  proxy, beans, components
Бизнес-логика  GoF, SOLID, DI
Security  Spring security, ACL
Security  OAuth2, JWT
Security  Хранение паролей
Web, Network  SpringMVC, WebFlux
Web, Network  HTTP, TLS, WebSocket
Web, Network  Browser, cors, cookies
Web, Network  REST
Web, Network  React, JS
Интеграции  Spring Integration
Интеграции  SOAP, WebServices
Интеграции  JMS, MQ, Kafka
Архитектура  Spring Cloud, Microservices
Архитектура  Проектирование API и БД, версионирование
Архитектура  Кэширование, горизонтальное масштабирование
Сборка и деплой  Spring Boot
Сборка и деплой  Gradle, Maven, AppServer
Сборка и деплой  Docker, k8s
Сборка и деплой  CI/CD инструменты
Сборка и деплой  bash, ssh, Linux, nginx
Процесс разработки  git, gitflow, squash
Процесс разработки  unit-tests, api-tests, e2e
Процесс разработки  code-review, code-style
Процесс разработки  Поддержка, мониторинг
Общее  Задача на сообразительность
Общее  Предыдущий проект
* Garbage Collector
+ Serial Garbage Collector. Single thread. Stop the world event
+ Parallel Garbage Collector. Multiple threads. Stop the world event
+ Concurrent Mark Sweep (CMS) Garbage Collector
+ Garbage First (G1) Garbage Collector. The Eden, survivors, and old areas use this equal-sized regions
* JVM
+ A specification where working of Java Virtual Machine is specified. But implementation provider is independent to choose the algorithm. Its implementation has been provided by Oracle and other companies.
+ An implementation Its implementation is known as JRE (Java Runtime Environment).
+ Runtime Instance Whenever you write java command on the command prompt to run the java class, an instance of JVM is created.

*The JVM performs following operation:*
+ Loads code
+ Verifies code
+ Executes code
+ Provides runtime environment
*JVM provides definitions for the:*
+ Memory area
+ Class file format
+ Register set
+ Garbage-collected heap
+ Fatal error reporting etc.

*Classloader*
+ =Bootstrap ClassLoader= - This is the first classloader which is the super class of Extension classloader. It loads the rt.jar file which contains all class files of Java Standard Edition like java.lang package classes, java.net package classes, java.util package classes, java.io package classes, java.sql package classes etc.
+ =Extension ClassLoader= - This is the child classloader of Bootstrap and parent classloader of System classloader. It loades the jar files located inside $JAVA_HOME/jre/lib/ext directory.
+ =System/Application ClassLoader= - This is the child classloader of Extension classloader. It loads the classfiles from classpath. By default, classpath is set to current directory. You can change the classpath using "-cp" or "-classpath" switch. It is also known as Application classloader.

=Just-In-Time(JIT)= compiler - it is used to improve the performance. JIT compiles parts of the byte code that have similar functionality at the same time, and hence reduces the amount of time needed for compilation. Here, the term "compiler" refers to a translator from the instruction set of a Java virtual machine (JVM) to the instruction set of a specific CPU.
https://www.javatpoint.com/jvm-java-virtual-machine
* Docker & Kubernetes
[[https://platform9.com/blog/kubernetes-service-discovery-principles-in-practice/]]

FROM, ADD, EXPOSE
 
*building*
docker build -t name:tag -p host_port:container_port
-d - run in detached mode
 
*terminate and remove container*
docker rm -f <id>
 
*view*
docker ps
docker ps -a [even stopped containers]

*reclaim*
docker system prune [removes all not used containers data]
 
Jib - separate resouces, codebase and dependencies of java application in different layers, not requires docker daemon

** multistage docker example
#+begin_src docker
FROM maven:3.5-jdk-8 as BUILD
 
#ADD repository.tar.gz /usr/share/maven/ref/
 
COPY . /usr/src/app
WORKDIR /usr/src/app
RUN mvn -s /usr/share/maven/ref/settings-docker.xml package
 
FROM openjdk:8-jre
EXPOSE 8080 5005
COPY --from=BUILD /usr/src/app/target /opt/target
WORKDIR /opt/target
ENV _JAVA_OPTIONS '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005'
 
CMD ["java", "-jar", "greeting.war"]
#+end_src

 
** pom.xml example:
<profile>
            <id>docker</id>
            <build>
                <plugins>
                    <plugin>
                        <groupId>io.fabric8</groupId>
                        <artifactId>docker-maven-plugin</artifactId>
                        <version>0.20.1</version>
                        <configuration>
                            <images>
                                <image>
                                    <name>hellojava</name>
                                    <build>
                                        <from>openjdk:latest</from>
                                        <assembly>
                                            <descriptorRef>artifact</descriptorRef>
                                        </assembly>
                                        <cmd>java -jar maven/${project.name}-${project.version}.jar</cmd>
                                    </build>
                                    <run>
                                        <wait>
                                            <log>Hello World!</log>
                                        </wait>
                                    </run>
                                </image>
                            </images>
                        </configuration>
                        <executions>
                            <execution>
                                <id>docker:build</id>
                                <phase>package</phase>
                                <goals>
                                    <goal>build</goal>
                                </goals>
                            </execution>
                            <execution>
                                <id>docker:start</id>
                                <phase>install</phase>
                                <goals>
                                    <goal>run</goal>
                                    <goal>logs</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                </plugins>
            </build>
        </profile>
 
* Maven
https://cguntur.me/2020/06/03/understanding-apache-maven-part-5/
*Google Best Practices for Java Libraries*
https://jlbp.dev/

*run only project_to_build and all transitive deps*
mvn -am -pl :path_of_project_to_build compile

* Liquibase
https://mydeveloperplanet.com/2020/04/21/easy-database-migration-with-liquibase/
* Jackson
Using @JsonTypeInfo annotation to handle polymorphic types
[[https://www.logicbig.com/tutorials/misc/jackson/jackson-json-type-info-annotation.html]]
* Versioning
[[https://helpercode.com/2020/12/29/versioning-multiple-micro-services-in-a-monorepo-using-maven/]]
* DDD
[[http://www.odrotbohm.de/2020/03/Implementing-DDD-Building-Blocks-in-Java/]]
* Algorithms
** Java Data Structures
=ArayDeque= add[Last](E) add to the end, remove[First]() - removes first element (head)), peek())
** BIg O
- 2^(logN) = N

- tree structure (ex: Fibonachi): O(branches^tree depth) (ex: Fibonachi - O(2^N)) called exponential

- for i .. N: for i+1 .. N
  N(N-1)/2 -> O(N^2)

- String sorting adds comparison complexity - O(s), s - max string length

- Factorial: N! -> O(N)

- multiple recursive calls, memoization could be used to store previous results of calculation O(N)
** Fibonachi
#+begin_src python
def fib(n, mem, k):
    if n < 0: return (0, k)
    if n == 0 or n == 1: return (n, k)
    if n in mem: return (mem[n], k)
    mem[n] = fib(n-2, mem, k+1)[0] + fib(n-1, mem, k+1)[0]
    return (mem[n], k)

mem = {}
for i in range(10):
    v = fib(i, mem, 0)
    print(" "*v[1], v[0])
#+end_src
** Trees
=Binary search tree= - binary tree in which evey node fits a specific ordering property: all left descendents <= n < all right descendents for each node n.
#+begin_src java
public static void traverseInOrder(TreeNode n) {
        if (n != null) {
            traverseInOrder(n.left);
            visit(n.val);
            traverseInOrder(n.right);
        }
    }
#+end_src
=Min heap= - min-heaps complete binary tree with each node smaller than it's children (root node - smalest value). =Max heap= is opposite. Operations: *insert* at the bottom right and then swap, *extract_min* - removing with replacing with bottomness right and swapping. Both O(log n) time.
** Graphs
=BFS= - when tree is not too wide, uses queue, =DFS= - recursion, always mark visited.

Bi-directional BFS for finding shortest path between 2 nodes
* resume words
https://ep-advisory.com/ru/statii/250-gotovyh-fraz-dlya-rezyume-i-sobesedovaniya-na-anglijskom/
more https://www.themuse.com/advice/185-powerful-verbs-that-will-make-your-resume-awesome

* RabbitMQ / AMQP
https://spring.io/blog/2010/06/14/understanding-amqp-the-protocol-used-by-rabbitmq/
https://habr.com/ru/company/itsumma/blog/416629/
RPC example https://github.dev/janitham/rabbitmq-spring-boot-rpc-worker, https://reflectoring.io/amqp-request-response/

Exchange'и и очереди
+ Паблишеры (publishers) отправляют сообщения на exchange’и
+ Exchange’и отправляют сообщения в очереди и в другие exchange’и на основе биндингов
+ RabbitMQ отправляет подтверждения паблишерам при получении сообщения
+ Получатели (consumers) поддерживают постоянные TCP-соединения с RabbitMQ и объявляют, какую очередь(-и) они получают
+ RabbitMQ проталкивает (push) сообщения получателям
+ Получатели отправляют подтверждения успеха/ошибки
+ После успешного получения, сообщения удаляются из очередей

Существует четыре типа exchange’ей и связанные с ними биндинги:

+ Fanout (разветвляющий). Направляет во все очереди и обменники, имеющие привязку к exchange’у Стандартная подмодель Pub.
+ Direct (прямой). Маршрутизирует сообщения на основе ключа маршрутизации, который несет с собой сообщение, задается паблишером. Ключ маршрутизации — короткая строка. Прямые обменники отправляют сообщения в очереди/exchange’и, у которых есть ключ сопряжения, который точно соответствует ключу маршрутизации.
+ Topic (тематический). Маршрутизирует сообщения на основе ключа маршрутизации, но позволяет использовать неполное соответствие (wildcard). '#' matches zero or more dot-delimited words and '*' matches exactly one such word
+ Header (заголовочный). RabbitMQ позволяет добавлять к сообщениям заголовки получателей. Заголовочные exchange’и передают сообщения в соответствии с этими значениями заголовка. Каждая привязка включает в себя точное соответствие значений заголовка. К привязке можно добавить несколько значений с ЛЮБЫМИ или ВСЕМИ значениями, необходимыми для соответствия.
+ Consistent Hashing (консистентное хэширование). Это обменник, который хэширует либо ключ маршрутизации, либо заголовок сообщения, и отправляет только в одну очередь. Это полезно, когда вам нужно соблюсти гарантии порядка обработки и при этом иметь возможность масштабировать получателей.

*Message content*
Headers
Properties
byte[] data
  
+ One queue and multiple consumers - concurrent consumers
+ Each queue will recieve same message (but filtered by bindings)


#+DOWNLOADED: screenshot @ 2022-01-09 22:55:36
[[file:attachments/RabbitMQ_/_AMQP/2022-01-09_22-55-36_screenshot.png]]

* Microservices questions
Асинхронность/Обработка ошибок;
Трафик/Кэши;
Распределенные транзакции/Согласованность;
Логи/Отладка;
Версионирование;
Люди/Шаринг/Рефакторинг


* Behavioral interview
+ Questions
  
Conflicts - In a team, with a customer, with another developer/team, with a manager.
How you worked with a final customer
Example of Failure
Example of Brave decision
Example of Latest Challenging task
Work with Ambiguity
How you express difficult concepts for non technical people

истории про последние два проекта и вашу роль в  них

"Tell me about your recently implemented task." рассказал о своей одной из последних тасок которую считал наиболее подходящей, немного в красках и с восторгом
" Imagine you work with someone in a team with who it is really hard to talk. How would you collaborate with him and try to get consensus for some task?" Сказал что говорил бы с этим человеком через кого кто для нее авторитет, или выносил бы эти вопросы на митинг со всей командой
" Imagine you work in a company with a bad culture, what would you do in this situation?" сказал что не молчал бы а рассказывал бы начальству о том какая культура в компании, может он об этом даже не знает, если бы меня не слушали то присоединился поддержкой людей, которые разделывают мои взгляды
"Imagine you are a director of a company with a bad culture, what would you do in this situation?" Сказал что говорил бы с подчиненными чтобы узнать что им не нравится, старался бы решить эти проблемы, трансформировать компанию как-то, если бы не получалось, то приобщился бы помощью специалистов - соответствующих консультантов
" Describe how organized development process in your team." описал процесс как есть, только в красках и с эпитетами

* System design

Questions
+ Who is going to use it?
+ How are they going to use it?
+ How many users are there?
+ What does the system do?
+ What are the inputs and outputs of the system?
+ How much data do we expect to handle?
+ How many requests per second do we expect?
+ What is the expected read to write ratio?

Систем дизайн.
Пришел парень, тимлид, 10 лет в гугле. Попросил спроектировать key/value storage из которого только читают. Постановка задачи звучала ровно так.

Я начал задавать уточняющие вопросы:
 1) Какой размер ключей и значений, какой тип данных? key 1КB string и val 10KB binary
 2) Сколько всего пар будем хранить в нашем сторадже? 5 млрд.
 3) Какая нагрузка на чтение? 100к запросов в секунду.
 4) Какое железо у меня есть? 32CPU/256GB RAM/10 Gbit net/ 10 * 6 Tb HDD
 5) Какие к сервису предъявлены SLO? 95% req < 50 ms и availability 99.99%

Далее начали считать цифры, сколько всего нужно места для хранения такого объема, сколько сети. На это было потрачено больше всего времени, было разрешено юзать калькулятор в телефоне. В итоге вышло, что для ключей надо 51.2 Tb  и для значений в районе 500Tb. Затем начался разговор про то, как будем хранить на диске или в памяти. Далее речь зашла про время позиционирования головки жесткого диска и количество iops на каждый диск. Я предложил для старта хранить все в RAM. Расчеты показали, что при текущем железе, надо 2.3к серверов, предложенной конфигурации. 
Далее сказал, что мы можем сэкономить потребление памяти и часть данных хранить на диске или использовать SSD, вместо HDD. Сказал про LRU кэш и на этом время закончилось.

* What to ask
How big is the company?
Why did you choose to work here?
Do you enjoy this particular project?
Is there flexibility within the org to move around to different projects?
What's a typical day like?
Software dev process? (agile/tdd/pairing?)
Bug tracking system?
Version control system?
Dev. desktop vs server OS? Developer machine hardware?
Is the product live in production? If not, what's the schedule for developing it?
How often are releases done?
Who supports the product once it's released? Pager duty? Monitoring email?
Where do feature + bugfix requests come from?
Who does the "design" of the product? Internal designers, devs, both?
Would my work be full-stack, or focused on backend/frontend?
How big is the code base? Lots of ties to external/legacy projects?
Typical working hours? Flexibility? Crunch times?
Working from home? Regularly vs. Snow days?
Do you have a favorite part of the job? Least favorite?
Do you have a time tracking system?
Centralized IT dept?
Gov’t contractor? Clearance required? Potential for clearance?
Regulatory compliance? PCI, SOX, etc. Annual training?
Do people hang out outside work? Company outings? Lunch?
Budget for conferences?
Internal lightning talks/brown bag lunches?
Does the company seem stable? Profitable? Any plans to sell?
Bonus structure?
Management style/structure? Frequent catch-ups aka one-on-ones? Something else?
Room for advancement?
Learning opportunities?

* Designing Data intensive applications book
+ Reliability
The system should continue to work correctly (performing the correct function at
the desired level of performance) even in the face of adversity (hardware or soft‐
ware faults, and even human error). See “Reliability” on page 6.
+ Scalability
As the system grows (in data volume, traffic volume, or complexity), there should
be reasonable ways of dealing with that growth. See “Scalability” on page 10.
+ Maintainability
Over time, many different people will work on the system (engineering and oper‐
ations, both maintaining current behavior and adapting the system to new use
cases), and they should all be able to work on it productively. See “Maintainabil‐
ity” on page 18.

** Performance
- througput - number of request which we can proceed per sec | total time to run a jub of a certain size
- latency - duration that request is waiting to be handling

For calculate average response time it's Better to use *percentiles*. Median is *p50* 50th percentile.

For example, if the 95th percentile response time is 1.5 seconds, that means 95 out of 100 requests take less than 1.5 seconds, and 5 out of 100 requests take 1.5 seconds or more.

An application has to meet various requirements in order to be useful. There are
*functional requirements* (what it should do, such as allowing data to be stored,
retrieved, searched, and processed in various ways), and some *nonfunctional requirements* (general properties like security, reliability, compliance, scalability, compatibility, and maintainability)

=Reliability= means making systems work correctly, even when faults occur (Fault-tolerance techniques can hide certain types of faults)
=Scalability= means having strategies for keeping performance good, even when load
increases
=Maintainability= has many facets, but in essence it’s about making life better for the engineering and operations teams. pGood abstractions can help reduce complexity and make the system easier to modify and adapt for new use cases. Good operability means having good visibility into the system’s health

** Data Models
*** SQL
*** NoSql
**** Document (MongoDb)
+ A need for greater scalability than relational databases can easily achieve
+ Specialized query operations that are not well supported by the relational model
+ Frustration with the restrictiveness of relational schemas, and a desire for a more dynamic and expressive data model (ex: JSON model reduces the impedance mismatch between the application code and the storage layer)

The main arguments in favor of the document data model are schema flexibility, better performance due to locality, and that for some applications it is closer to the data structures used by the application. The relational model counters by providing better support for joins, and many-to-one and many-to-many relationships.

**** Graph-Like (Neo4j)
A graph consists of two kinds of objects: vertices (also known as nodes or entities) and edges (also known as relationships or arcs). Many kinds of data can be modeled as a graph. Typical examples include: Social graphs, The web graph, Road or rail networks (Neo4j)

*** Quering types
=Declerative= (sql)
=MapReduce= is a programming model for processing large amounts of data in bulk
across many machines, popularized by Google (Mongodb)

** Storage and retrieval
*** Indexes
**** Hash Indexes
Let’s say our key-value data storage consists only of appending to a file, then the simplest possible indexing strategy is this: keep an in-memory hash map where every key is mapped to a byte offset in the data file.
Whenever you append a new key-value pair to the file, you also update the hash map to reflect the offset of the data you just wrote (same for updating)

We only ever append to a file, so how do we avoid eventually running out of disk space? A good solution is to break the log into segments of a certain size by closing a segment file when it reaches a certain size, and making subsequent writes to a new segment file. We can then perform *compaction* on these segments. Compaction means throwing away duplicate keys in the log, and keeping only the most recent update for each key.

The merging and compaction of frozen segments can be done in a background thread, and while it is going on, we can still continue to serve read and write requests as normal, using the old segment files. After the merging process is complete, we switch read requests to using the new merged segment instead of the old segments—and then the old segment files can simply be deleted.
**** SSTables and LSM-Trees
Store graph of keys in graph (maintaining sorted order) first in-memory and then save on disk.
**** B-Trees
B-trees break the database down into fixed-size blocks or pages, traditionally 4 KB in size (sometimes bigger), and read or write one page at a time. This design corresponds more closely to the underlying hardware, as disks are also arranged in fixed-size blocks.
B-trees keep key-value pairs sorted by key, which allows efficient key-value
lookups and range queries
One page is designated as the root of the B-tree; whenever you want to look up a key in the index, you start here. The page contains several keys and references to child pages. Each child is responsible for a continuous range of keys, and the keys between the references indicate where the boundaries between those ranges lie.

write-ahead log
*** Modes of Dataflow
**** REST
REST is not a protocol, but rather a design philosophy that builds upon the principles of HTTP. It emphasizes simple data formats, using URLs for identifying resources and using HTTP features for cache control, authentication, and content type negotiation. REST has been gaining popularity compared to SOAP, at least in the context of cross-organizational service integration, and is often associated with microservices. An API designed according to the principles of REST is called RESTful.
**** SOAP
SOAP is an XML-based protocol for making network API requests.
Although it is most commonly used over HTTP, it aims to be independent from
HTTP and avoids using most HTTP features. Instead, it comes with a sprawling and complex multitude of related standards (the web service framework, known as WS-) that add various features.
**** RPC
**** Messaging
=Message broker=
+ It can act as a buffer if the recipient is unavailable or overloaded, and thus improve system reliability.
+ It can automatically redeliver messages to a process that has crashed, and thus prevent messages from being lost.
+ It avoids the sender needing to know the IP address and port number of the recipient (which is particularly useful in a cloud deployment where virtual machines often come and go).
+ It allows one message to be sent to several recipients.
+ It logically decouples the sender from the recipient (the sender just publishes messages and doesn’t care who consumes them).
*** Distributed Data
Reasons why you might want to distribute a database across multi‐
ple machines:
+ Scalability
If your data volume, read load, or write load grows bigger than a single machine can handle, you can potentially spread the load across multiple machines.
+ Fault tolerance/high availability
If your application needs to continue working even if one machine (or several machines, or the network, or an entire datacenter) goes down, you can use multiple machines to give you redundancy. When one fails, another one can take over.
+ Latency
If you have users around the world, you might want to have servers at various locations worldwide so that each user can be served from a datacenter that is geographically close to them. That avoids the users having to wait for network packets to travel halfway around the world.

**** Scaling to higher load
If all you need is to scale to higher load, the simplest approach is to buy a more powerful machine (sometimes called *vertical scaling* or *scaling up*).

1. The problem with a *shared-memory approach* is that the cost grows faster than linearly: a machine with twice as many CPUs, twice as much RAM, and twice as much disk capacity as another typically costs significantly more than twice as much. And due to bottlenecks, a machine twice the size cannot necessarily handle twice the load.

2. Another approach is the *shared-disk architecture*, which uses several machines with independent CPUs and RAM, but stores data on an array of disks that is shared between the machines, which are connected via a fast network.

By contrast, *shared-nothing architectures* (*horizontal scaling* or *scaling out*) have gained a lot of popularity. In this approach, each machine or virtual machine running the database software is called a node. Each node uses its CPUs, RAM, and disks independently. Any coordination between nodes is done at the software level, using a conventional network.

**** Replication
There are two common ways data is distributed across multiple nodes: Rerlication and Partitioning

=Replication= keeping a copy of the same data on several different nodes, potentially in different locations. Replication provides redundancy: if some nodes are unavailable, the data can still be served from the remaining nodes. Replication can also help improve performance.

+ To keep data geographically close to your users (and thus reduce latency)
+ To allow the system to continue working even if some of its parts have failed (and thus increase availability)
+ To scale out the number of machines that can serve read queries (and thus increase read throughput)

Three popular algorithms for replicating changes between nodes: *single-leader*, *multi-leader*, and *leaderless* replication.

1. One of the replicas is designated the *leader* (also known as master or primary). When clients want to write to the database, they must send their requests to the leader, which first writes the new data to its local storage.
2. The other replicas are known as followers (read replicas, slaves, secondaries, or hot standbys). Whenever the leader writes new data to its local storage, it also sends the data change to all of its followers as part of a replication log or change stream. Each follower takes the log from the leader and updates its local copy of the database accordingly, by applying all writes in the same order as they were processed on the leader.
3. When a client wants to read from the database, it can query either the leader or any of the followers. However, writes are only accepted on the leader (the followers are read-only from the client’s point of view).

*Synchronous/assynchronous* - whenether master should wait untill all slaves applied changes. Usualy 1 sync and others assync.
**** Partitioning
Splitting a big database into smaller subsets called partitions so that different partitions can be assigned to different nodes (also known as *sharding*).
